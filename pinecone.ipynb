{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████| 1.52k/1.52k [00:00<00:00, 89.2kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 191/191 [00:00<?, ?B/s] \n",
      "README.md: 100%|██████████| 90.3k/90.3k [00:00<00:00, 343kB/s]\n",
      "config.json: 100%|██████████| 779/779 [00:00<00:00, 64.8kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 124/124 [00:00<?, ?B/s] \n",
      "model.safetensors: 100%|██████████| 1.34G/1.34G [01:42<00:00, 13.0MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.34G/1.34G [02:14<00:00, 9.98MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 52.0/52.0 [00:00<00:00, 8.22kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 8.50kB/s]\n",
      "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 9.50MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 366/366 [00:00<00:00, 36.1kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.26MB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 50.8kB/s]\n"
     ]
    }
   ],
   "source": [
    "# ## BGE Embeddings\n",
    "# from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "# encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "# device = \"cpu\"\n",
    "# bge_embeddings = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs={'device': device},\n",
    "#     encode_kwargs=encode_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "device = \"cpu\"\n",
    "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(bge_embeddings.embed_query(\"hello world, iron man\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langchain.document_loaders import DirectoryLoader\n",
    "# from langchain.document_loaders import TextLoader\n",
    "# loader = DirectoryLoader('doc_txt/', glob=\"**/*.text\", \n",
    "#                          loader_cls=TextLoader, \n",
    "#                          use_multithreading=True,\n",
    "#                          show_progress=True)\n",
    "# docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patent_jsons\\JP-H10177520-A.json\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "\n",
    "vectors = []\n",
    "\n",
    "folder = \"patent_jsons\"\n",
    "files = [os.path.join(folder, f) for f in os.listdir(folder) ]\n",
    "\n",
    "print(files[1])\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JP-H10177520-A\n"
     ]
    }
   ],
   "source": [
    "print(files[1][13:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors:   0%|          | 0/500 [2:29:41<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i,path in enumerate(files):\n",
    "    if i>=0:\n",
    "        data = {\"id\":f\"{i}\",\n",
    "                \"values\":None, \n",
    "                \"metadata\":{\"file_name\": path[13:-5],\n",
    "                            \"title\":None, \n",
    "                            \"lang\":None}}\n",
    "\n",
    "        with open(path, \"r\") as read_file:\n",
    "            doc = json.load(read_file)\n",
    "            # print(len(doc[\"descriptions\"]))\n",
    "            # if not os.path.exists(\"doc_txt\"):\n",
    "            #     os.mkdir(\"doc_txt\")\n",
    "            for file in doc[\"descriptions\"]:\n",
    "                if file[\"lang\"]==\"EN\":\n",
    "                    data[\"metadata\"][\"lang\"]=\"EN\"\n",
    "                    html_data = file[\"paragraph_markup\"]\n",
    "                    # Extract the paragraph_markup from the data\n",
    "\n",
    "                    soup = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "                    # Extract all text from the HTML structure\n",
    "                    all_text = soup.get_text(separator='\\n', strip=True)\n",
    "                    # data[\"metadata\"][\"content\"]=all_text\n",
    "                    \n",
    "                    # with open(f\"doc_txt/doc_{i}.text\", \"w\") as write_file:\n",
    "                    #     write_file.write(all_text)\n",
    "                    \n",
    "            # if not os.path.exists(\"title_txt\"):\n",
    "            #     os.mkdir(\"title_txt\")\n",
    "            for title in doc[\"titles\"]:\n",
    "                if title[\"lang\"]==\"EN\":\n",
    "                    title_data = title[\"text\"]\n",
    "                    \n",
    "                    # with open(f\"title_txt/title_{i}.text\", \"w\") as write_file:\n",
    "                    #     write_file.write(title_data)\n",
    "        data[\"metadata\"][\"title\"]=title_data\n",
    "        data[\"values\"] = bge_embeddings.embed_query(title_data+all_text)\n",
    "        vectors.append(data)          \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating pinecone db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dotenv\n",
    "# dotenv.load_dotenv()\n",
    "import os \n",
    "# api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "pinecone.init(api_key=\"c9fa65e7-443c-4c12-bea1-0b835c561d9d\", environment=\"gcp-starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index('first-index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|██████████| 500/500 [00:07<00:00, 63.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 500}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert(vectors=vectors, batch_size=50, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Retrieving full documents rather than chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"Data processing apparatus having high speed slave store and multi-word instruction buffer\"\n",
    "query_emb = bge_embeddings.embed_query(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pinecone \n",
    "\n",
    "# pinecone.init(api_key='YOUR_API_KEY', environment='us-east1-gcp') \n",
    "# index = pinecone.Index('example-index') \n",
    "\n",
    "query_response = index.query(\n",
    "    # namespace='example-namespace',\n",
    "    top_k=5,\n",
    "    include_values=False,\n",
    "    include_metadata=True,\n",
    "    vector=query_emb,\n",
    "    # sparseVector={\n",
    "    #     'indices': [10, 45, 16],\n",
    "    #     'values':  [0.5, 0.5, 0.2]\n",
    "    # },\n",
    "    # filter={\n",
    "    #     'genre': {'$in': ['comedy', 'documentary', 'drama']}\n",
    "    # }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(query_response[\"matches\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '8',\n",
      " 'metadata': {'file_name': 'US-3949376-A',\n",
      "              'lang': 'EN',\n",
      "              'title': 'Data processing apparatus having high speed slave '\n",
      "                       'store and multi-word instruction buffer'},\n",
      " 'score': 0.903763354,\n",
      " 'values': []}, {'id': '53',\n",
      " 'metadata': {'file_name': 'US-5179680-A',\n",
      "              'lang': 'EN',\n",
      "              'title': 'Instruction storage and cache miss recovery in a high '\n",
      "                       'speed multiprocessing parallel processing apparatus'},\n",
      " 'score': 0.801680863,\n",
      " 'values': []}, {'id': '49',\n",
      " 'metadata': {'file_name': 'US-5123097-A',\n",
      "              'lang': 'EN',\n",
      "              'title': 'APPARATUS AND METHOD FOR SIMULTANEOUS EXECUTION OF A '\n",
      "                       'WRITE INSTRUCTION AND A SUCCEEDING READ INSTRUCTION IN '\n",
      "                       'A DATA PROCESSING SYSTEM WITH A STORE THROUGH CACHE '\n",
      "                       'STRATEGY'},\n",
      " 'score': 0.793522835,\n",
      " 'values': []}, {'id': '212',\n",
      " 'metadata': {'file_name': 'US-5860107-A',\n",
      "              'lang': 'EN',\n",
      "              'title': 'Processor and method for store gathering through '\n",
      "                       'merged store operations'},\n",
      " 'score': 0.783657491,\n",
      " 'values': []}, {'id': '419',\n",
      " 'metadata': {'file_name': 'US-6505295-B1',\n",
      "              'lang': 'EN',\n",
      "              'title': 'Data processor'},\n",
      " 'score': 0.779720247,\n",
      " 'values': []}]\n"
     ]
    }
   ],
   "source": [
    "print(query_response[\"matches\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"patent_jsons\"\n",
    "files = [os.path.join(folder, f) for f in os.listdir(folder) ]\n",
    "\n",
    "db_patent = \"patent_files.json\"\n",
    "if not os.path.exists(db_patent):\n",
    "    db = {\"data\":{}}\n",
    "    with open(db_patent, \"w\") as write_file:\n",
    "        json.dump(db, write_file, indent=4)\n",
    "\n",
    "    for i,path in enumerate(files):\n",
    "        if i>=0:\n",
    "            data = {\"html_data\": None, \"title\":None}\n",
    "            with open(path, \"r\") as read_file:\n",
    "                doc = json.load(read_file)\n",
    "                for file in doc[\"descriptions\"]:\n",
    "                    if file[\"lang\"]==\"EN\":\n",
    "                        html_data = file[\"paragraph_markup\"]\n",
    "\n",
    "\n",
    "                for title in doc[\"titles\"]:\n",
    "                    if title[\"lang\"]==\"EN\":\n",
    "                        title_data = title[\"text\"]\n",
    "\n",
    "            data[\"title\"]=title_data\n",
    "            data[\"html_data\"] = html_data\n",
    "\n",
    "            with open(db_patent, \"r\") as read_file:\n",
    "                db_loaded = json.load(read_file)\n",
    "                db_loaded[\"data\"][path[13:-5]]=data\n",
    "\n",
    "            with open(db_patent, \"w\") as write_file:\n",
    "                json.dump(db_loaded, write_file, indent=4)\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
